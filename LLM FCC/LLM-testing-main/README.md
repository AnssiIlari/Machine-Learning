# Large Language Model (LLM) from Scratch

## Overview
This repository documents my journey in building a Large Language Model (LLM) from scratch, following the guidelines of FreeCodeCamp's course "Create a Large Language Model from Scratch with Python". The model training was conducted on Google Colab for efficient resource management and scalability.

### Key Features
- **FreeCodeCamp Course Implementation:** Step-by-step implementation of the LLM as per the course guidelines.
- **Google Colab Utilization:** Utilization of Google Colab's powerful computing resources for model training.
- **OpenWebTextCorpus:** Training material sourced from the comprehensive and diverse [OpenWebTextCorpus](https://skylion007.github.io/OpenWebTextCorpus/).

## Repository Contents
- `data-extract.py`: Python script for splitting and preparing the training data from OpenWebTextCorpus.
- `Model_Training_Notebooks/`: Jupyter notebooks used in Google Colab for training the model.

## Model Access
The model, trained approximately 10,000 times, is available for download and experimentation:
[Download Trained Model](https://drive.google.com/file/d/12JbMW_k069JNSWhI2e6YWnsV8wrVL_iH/view?usp=sharing)


*Last Updated: 23rd December 2023*
